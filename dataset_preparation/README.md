
<h1> Dataset Preparation</h1>

###We recommend downloading the datasets and benchmarks as follows
Download all the datasets and benchmarks
```bash
source scripts/bash_scripts/download_data.sh all 
```
Download a specific dataset and benchmark with examples
```bash
source scripts/bash_scripts/download_data.sh <search_space> <dataset> 
source scripts/bash_scripts/download_data.sh nb201 cifar10
source scripts/bash_scripts/download_data.sh nb201 all 
```
Download the TransNAS-Bench-101 benchmark from [here](https://www.noahlab.com.hk/opensource/vega/page/doc.html?path=datasets/transnasbench101) and place in the folder `naslib/data/..`


### If this does not work for you please follow the steps below

Simply download the benchmark data files from the these URLs and place them in `naslib/data`.

| Benchmark     | Task                               | Datasets | Data URL                                                                                                                                                                                                                                                                                                                                                                                         | Required Files                                                                                                                                                                                                                                                                |
|---------------|------------------------------------|----------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
|NAS-Bench-101  | Image Classification   |                    CIFAR10                   | [cifar10](https://drive.google.com/file/d/1oORtEmzyfG1GcnPHh0ijCs0gCHKEThNx/view?usp=sharing)                                                                                                                                                                                                                                                                                                    | `naslib/data/nasbench_only108.pkl`                                                                                                                                                                                                                                            |
|NAS-Bench-201  | Image Classification   |  CIFAR10 <br> CIFAR100 <br> ImageNet16-120   | [cifar10](https://drive.google.com/file/d/1sh8pEhdrgZ97-VFBVL94rI36gedExVgJ/view?usp=sharing) <br> [cifar100](https://drive.google.com/file/d/1hV6-mCUKInIK1iqZ0jfBkcKaFmftlBtp/view?usp=sharing) <br> [imagenet](https://drive.google.com/file/d/1FVCn54aQwD6X6NazaIZ_yjhj47mOGdIH/view?usp=sharing) | `naslib/data/nb201_cifar10_full_training.pickle` <br> `naslib/data/nb201_cifar100_full_training.pickle` <br>  `naslib/data/nb201_ImageNet16_full_training.pickle`                                                                    |
|NAS-Bench-301  | Image Classification   |                    CIFAR10                   | [cifar10](https://drive.google.com/file/d/1YJ80Twt9g8Gaf8mMgzK-f5hWaVFPlECF/view?usp=sharing) <br> [models](https://figshare.com/articles/software/nasbench301_models_v1_0_zip/13061510)                                                                                                                                                                                                         | `naslib/data/nb301_full_training.pickle` <br> `naslib/data/nb_models/...`                                                                                                                                                                                                     |
|NAS-Bench-ASR  | Automatic Speech Recognition  |               TIMIT                   | [timit](https://github.com/SamsungLabs/nb-asr/releases/tag/v1.1.0)                                                                                                                                                                                                                                                                                                                               | `naslib/data/nb-asr-bench-gtx-1080ti-fp32.pickle` <br> `naslib/data/nb-asr-bench-jetson-nano-fp32.pickle` <br> `naslib/data/nb-asr-e40-1234.pickle` <br> `naslib/data/nb-asr-e40-1235.pickle` <br> `naslib/data/nb-asr-e40-1236.pickle` <br> `naslib/data/nb-asr-info.pickle`
|NAS-Bench-NLP  | Natural Language Processing   |           Penn Treebank               | [ptb](https://drive.google.com/file/d/1DtrmuDODeV2w5kGcmcHcGj5JXf2qWg01/view?usp=sharing), [models](https://drive.google.com/file/d/13Kbn9VWHuBdSN3lG4Mbyr2-VdrTsfLfd/view?usp=sharing)                                                                                                                                                                                                          | `naslib/data/nb_nlp.pickle` <br> `naslib/data/nbnlp_v01/...`                                                                                                                                                                                                                  |
|TransNAS-Bench-101  | 7 Computer Vision tasks  |             Taskonomy                 | [taskonomy](https://www.noahlab.com.hk/opensource/vega/page/doc.html?path=datasets/transnasbench101)                                                                                                                                                                                                                                                                                             | `naslib/data/transnas-bench_v10141024.pth`                                                                                                                                                                                                                                    |

The ImageNet16-120 for `NAS-Bench-201` data could be downloaded from [here](https://drive.google.com/drive/folders/1NE63Vdo2Nia0V7LK1CdybRLjBFY72w40), and placed in the folder `naslib/data/ImageNet16-120/...`.

To setup the taskonomy dataset manually for the competition follow the steps below:
1. Download and unzip [rgb](http://downloads.cs.stanford.edu/downloads/taskonomy_data/rgb/benevolence_rgb.tar), [class_scene](http://downloads.cs.stanford.edu/downloads/taskonomy_data/class_scene/benevolence_class_scene.tar), [class_object](http://downloads.cs.stanford.edu/downloads/taskonomy_data/class_object/benevolence_class_object.tar
   ) for the benevolence dataset and place them in ```naslib/data/taskonomydata_mini/benevolence/``` as ```rgb```, ```class_object``` and ```class_scene``` directories respectively.
2. Download and unzip [rgb](http://downloads.cs.stanford.edu/downloads/taskonomy_data/rgb/forkland_rgb.tar), [class_scene](http://downloads.cs.stanford.edu/downloads/taskonomy_data/class_scene/forkland_class_scene.tar), [class_object](http://downloads.cs.stanford.edu/downloads/taskonomy_data/class_object/forkland_class_object.tar
   ) for the benevolence dataset and place them in ```naslib/data/taskonomydata_mini/forkland/``` as ```rgb```, ```class_object``` and ```class_scene``` directories respectively.
3.  Download and unzip [rgb](http://downloads.cs.stanford.edu/downloads/taskonomy_data/rgb/merom_rgb.tar), [class_scene](http://downloads.cs.stanford.edu/downloads/taskonomy_data/class_scene/merom_class_scene.tar), [class_object](http://downloads.cs.stanford.edu/downloads/taskonomy_data/class_object/merom_class_object.tar
    ) for the benevolence dataset and place them in ```naslib/data/taskonomydata_mini/merom/``` as ```rgb```, ```class_object``` and ```class_scene``` directories respectively.
