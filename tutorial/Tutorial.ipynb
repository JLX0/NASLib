{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "174aa05f",
   "metadata": {},
   "source": [
    "# Tutorial\n",
    "\n",
    "This tutorial assumes that you are completely new to NASLib, and will introduce you to the core ideas and APIs of the library. By the end of it, you will know everything you need to know to make a submission to the [Zero-Cost NAS Competition](link here)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636c78d4",
   "metadata": {},
   "source": [
    "## Introduction to Search Spaces\n",
    "\n",
    "Let's begin by taking a look [NAS-Bench-201](https://arxiv.org/abs/2001.00326) search space as an example:\n",
    "\n",
    "<img src=\"./images/nb201_arch.png\" alt=\"alt text\" title=\"image Title\" width=\"700\"/>\n",
    "\n",
    "As you can see, the architecture consists of multiple *cells* stacked together with residual blocks in between which downsample the feature maps. Each cell has 6 edges, each of which could hold one of 5 operations from a predefined operation set.\n",
    "\n",
    "Let's first create a search space in NASLib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf26de8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph makrograph-0.3161564, scope None, 20 nodes"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from naslib.search_spaces import NasBench201SearchSpace\n",
    "search_space = NasBench201SearchSpace(n_classes=10)\n",
    "search_space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722635fc",
   "metadata": {},
   "source": [
    "Equivalently, you could also create the search space as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75996eba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph makrograph-0.6456528, scope None, 20 nodes"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from naslib.search_spaces import get_search_space\n",
    "search_space = get_search_space(name='nasbench201', dataset='cifar10')\n",
    "search_space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c093ae5",
   "metadata": {},
   "source": [
    "`Graphs` in NASLib inherit from both [PyTorch Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html) as well as [NetworkX DiGraph](https://networkx.org/documentation/stable/reference/classes/digraph.html). It uses [NetworkX](https://networkx.org/) to create the architecture structure, which can later be parsed to create a standard PyTorch Module.\n",
    "\n",
    "Here's a closer look at the search_space graph that we just created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac8781f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes in the graph: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
      "Edges in the graph: [(1, 2), (2, 3), (3, 4), (4, 5), (5, 6), (6, 7), (7, 8), (8, 9), (9, 10), (10, 11), (11, 12), (12, 13), (13, 14), (14, 15), (15, 16), (16, 17), (17, 18), (18, 19), (19, 20)]\n"
     ]
    }
   ],
   "source": [
    "print('Nodes in the graph:', search_space.nodes())\n",
    "print('Edges in the graph:', search_space.edges())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baabb241",
   "metadata": {},
   "source": [
    "Every node and edge of the `Graph` can hold operations, which could be either a PyTorch `Module` or another `Graph`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0306eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operation on edge 1-2 of the graph: Stem(\n",
      "  (seq): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "Operation on edge 2-3 of the graph: Graph named 'cell' with 4 nodes and 6 edges\n"
     ]
    }
   ],
   "source": [
    "print('Operation on edge 1-2 of the graph:', search_space.edges[1, 2]['op']) # Pytorch Module as 'op' on the edge\n",
    "print('Operation on edge 2-3 of the graph:', search_space.edges[2, 3]['op']) # NASLib Graph as 'op' on the edge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d071e04",
   "metadata": {},
   "source": [
    "Here's a closer look at a cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b90506b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes in the cell: [1, 2, 3, 4]\n",
      "Edges in the cell: [(1, 2), (1, 3), (1, 4), (2, 3), (2, 4), (3, 4)]\n"
     ]
    }
   ],
   "source": [
    "cell = search_space.edges[2, 3]['op']\n",
    "print('Nodes in the cell:', cell.nodes())\n",
    "print('Edges in the cell:', cell.edges())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199f1118",
   "metadata": {},
   "source": [
    "The cell graph thus has the same structure as the cell shown in the NAS-Bench-201 architecture figure. Let's now look at what is present on the edges of the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db74b8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operations on edge 1-2 of cell:\n",
      "[Identity(), Zero (stride=1), ReLUConvBN(\n",
      "  (op): Sequential(\n",
      "    (0): ReLU()\n",
      "    (1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  )\n",
      "), ReLUConvBN(\n",
      "  (op): Sequential(\n",
      "    (0): ReLU()\n",
      "    (1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  )\n",
      "), AvgPool1x1(\n",
      "  (avgpool): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      ")]\n"
     ]
    }
   ],
   "source": [
    "print(f'Operations on edge 1-2 of cell:')\n",
    "print(cell.edges[1, 2]['op'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811af732",
   "metadata": {},
   "source": [
    "All edges on the cell have a list of candidate operations on them, as seen above. The candidate operations here are Identity, Zero, ReLU-3x3Convolution-BatchNorm, ReLU-1x1Convolution-BatchNorm, and a 1x1AveragePool. You can uncomment and run the next lines to see all the edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ffe636e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for edge in cell.edges:\n",
    "#     print('%'*50)\n",
    "#     print(f'Operations on edge 1-2 of cell:')\n",
    "#     print(cell.edges[edge]['op'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ab170f",
   "metadata": {},
   "source": [
    "## Sampling random models\n",
    "\n",
    "Let's now sample a random architecture from the search space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b43e541f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before sampling operation\n",
      "Operation on edge 1-2: [Identity(), Zero (stride=1), ReLUConvBN(\n",
      "  (op): Sequential(\n",
      "    (0): ReLU()\n",
      "    (1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  )\n",
      "), ReLUConvBN(\n",
      "  (op): Sequential(\n",
      "    (0): ReLU()\n",
      "    (1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  )\n",
      "), AvgPool1x1(\n",
      "  (avgpool): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      ")]\n",
      "\n",
      "After sampling operation\n",
      "Operation on edge (1, 2): Identity()\n",
      "Operation on edge (1, 3): ReLUConvBN(\n",
      "  (op): Sequential(\n",
      "    (0): ReLU()\n",
      "    (1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "Operation on edge (1, 4): Zero (stride=1)\n",
      "Operation on edge (2, 3): Zero (stride=1)\n",
      "Operation on edge (2, 4): Identity()\n",
      "Operation on edge (3, 4): ReLUConvBN(\n",
      "  (op): Sequential(\n",
      "    (0): ReLU()\n",
      "    (1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "Architecture encoding: (0, 2, 1, 1, 0, 3)\n"
     ]
    }
   ],
   "source": [
    "graph = search_space.clone() # Clone the search space first\n",
    "cell = graph.edges[2, 3]['op']\n",
    "show_only_one_edge = True\n",
    "\n",
    "# Initially, the operation on an edge is simply a list of all candidate operations\n",
    "print('Before sampling operation')\n",
    "print('Operation on edge 1-2:', cell.edges[1, 2]['op'])\n",
    "\n",
    "# Sample a random architecture\n",
    "graph.sample_random_architecture()\n",
    "\n",
    "# After sampling, it is replaced by one operation from the list\n",
    "print('\\nAfter sampling operation')\n",
    "for edge in cell.edges():\n",
    "    print(f'Operation on edge {edge}:', cell.edges[edge]['op'])\n",
    "\n",
    "# Get the representation of this architecture:\n",
    "print('\\nArchitecture encoding:', graph.get_hash())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db5c2f7",
   "metadata": {},
   "source": [
    "To create the PyTorch model, one needs only to parse this `Graph` as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f10785e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sub modules in the graph before parsing []\n",
      "\n",
      "Sub modules in the graph after parsing [Stem(\n",
      "  (seq): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "), Graph cell-0.3683700, scope stage_1, 4 nodes, Graph cell-0.7152342, scope stage_1, 4 nodes, Graph cell-0.8219054, scope stage_1, 4 nodes, Graph cell-0.5814143, scope stage_1, 4 nodes, Graph cell-0.6844618, scope stage_1, 4 nodes, ResNetBasicblock(\n",
      "  (conv_a): ReLUConvBN(\n",
      "    (op): Sequential(\n",
      "      (0): ReLU()\n",
      "      (1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (conv_b): ReLUConvBN(\n",
      "    (op): Sequential(\n",
      "      (0): ReLU()\n",
      "      (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (downsample): Sequential(\n",
      "    (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "), Graph cell-0.9210311, scope stage_2, 4 nodes, Graph cell-0.6900291, scope stage_2, 4 nodes, Graph cell-0.4307776, scope stage_2, 4 nodes, Graph cell-0.7351776, scope stage_2, 4 nodes, Graph cell-0.6478630, scope stage_2, 4 nodes, ResNetBasicblock(\n",
      "  (conv_a): ReLUConvBN(\n",
      "    (op): Sequential(\n",
      "      (0): ReLU()\n",
      "      (1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (conv_b): ReLUConvBN(\n",
      "    (op): Sequential(\n",
      "      (0): ReLU()\n",
      "      (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (downsample): Sequential(\n",
      "    (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    (1): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "), Graph cell-0.3437835, scope stage_3, 4 nodes, Graph cell-0.5114087, scope stage_3, 4 nodes, Graph cell-0.7046120, scope stage_3, 4 nodes, Graph cell-0.2255598, scope stage_3, 4 nodes, Graph cell-0.6411812, scope stage_3, 4 nodes, Sequential(\n",
      "  (op): Sequential(\n",
      "    (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): AdaptiveAvgPool2d(output_size=1)\n",
      "    (3): Flatten(start_dim=1, end_dim=-1)\n",
      "    (4): Linear(in_features=64, out_features=10, bias=True)\n",
      "  )\n",
      ")]\n",
      "\n",
      "Result: tensor([[-0.1394, -0.0561,  0.3482, -0.1860, -0.1104,  0.1221,  0.2481,  0.1997,\n",
      "         -0.4143, -0.2007]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create the graph\n",
    "graph = search_space.clone()\n",
    "graph.sample_random_architecture()\n",
    "\n",
    "# Parse the graph\n",
    "print('Sub modules in the graph before parsing', list(graph.children()))\n",
    "graph.parse()\n",
    "print('\\nSub modules in the graph after parsing', list(graph.children()))\n",
    "\n",
    "# Test the graph with a forward pass of a small random minibatch\n",
    "result = graph(torch.randn(1, 3, 32, 32))\n",
    "print('\\nResult:', result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf594896",
   "metadata": {},
   "source": [
    "## Querying the performance of a model\n",
    "\n",
    "NAS-Bench-201 has 15,625 models in its search space, all of which have been evaluated for classification task on three separate datasets - CIFAR10, CIFAR100, and ImageNet-16-120. Given the architecture encoding of a model, one can simply query the benchmark to see its final performance for any one of these tasks.\n",
    "\n",
    "The first thing to do is to ensure that you have the benchmark data files. For now, we will download and test only the NAS-Bench-201 benchmark for the CIFAR10 task. If you've already downloaded the data and tested the API, you can skip this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1ac43c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sh: scripts/bash_scripts/download_data.sh: No such file or directory\n",
      "python: can't open file 'test_benchmark_apis.py': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!sh scripts/bash_scripts/download_data.sh nb201 cifar10\n",
    "!python test_benchmark_apis.py --search_space nasbench201 --task cifar10 --show_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0e1535a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convenience function to sample a new model from the given search space and parse it\n",
    "def sample_and_parse_graph(name='nasbench201', dataset='cifar10'):\n",
    "    search_space = get_search_space(name, dataset)\n",
    "    search_space.sample_random_architecture()\n",
    "    search_space.parse()\n",
    "    return search_space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a819fd6",
   "metadata": {},
   "source": [
    "Now, lets sample a model from the search space and query its validation performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9272b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compact model representation is: (3, 4, 2, 1, 3, 0)\n",
      "NAS-Bench-201 representation is: |nor_conv_1x1~0|+|avg_pool_3x3~0|none~1|+|nor_conv_3x3~0|nor_conv_1x1~1|skip_connect~2|\n",
      "Validation accuracy: 88.47\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# First, load the benchmark API.\n",
    "from naslib.utils import get_dataset_api\n",
    "dataset_api = get_dataset_api('nasbench201', 'cifar10')\n",
    "\n",
    "# Sample a random architecture model\n",
    "graph = sample_and_parse_graph()\n",
    "\n",
    "# Show architecture encoding\n",
    "from naslib.search_spaces.nasbench201.conversions import convert_naslib_to_str\n",
    "\n",
    "print(f'Compact model representation is: {graph.get_hash()}')\n",
    "print(f'NAS-Bench-201 representation is: {convert_naslib_to_str(graph)}')\n",
    "\n",
    "# Query the benchmark\n",
    "from naslib.search_spaces.core.query_metrics import Metric\n",
    "val_accuracy = graph.query(\n",
    "    metric=Metric.VAL_ACCURACY,\n",
    "    dataset='cifar10',\n",
    "    dataset_api=dataset_api\n",
    ")\n",
    "\n",
    "print(f'Validation accuracy: {val_accuracy}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db9d44c",
   "metadata": {},
   "source": [
    "## Zero Cost Predictors\n",
    "Let's now move on to trying the zero cost predictors already available in NASLib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e2841c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Sampling 10 models...\n",
      "Scoring models with predictor ...\n",
      "Querying benchmarks for actual scores...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Evaluates a ZeroCost predictor for a search space and dataset/task\"\"\"\n",
    "from naslib.predictors import ZeroCost\n",
    "from naslib.utils import utils\n",
    "import numpy as np\n",
    "\n",
    "# Get the configs from naslib/configs/predictor_config.yaml (and the command line arguments, if any)\n",
    "# The configs include the zero-cost method to use, the search space and dataset/task to use,\n",
    "# amongst others.\n",
    "config = utils.get_config_from_args()\n",
    "# print(config)\n",
    "\n",
    "# Initialize the predictor\n",
    "# Method type can be \"fisher\", \"grasp\", \"grad_norm\", \"jacov\", \"snip\", \"synflow\", \"flops\" or \"params\"\n",
    "predictor = ZeroCost(config, batch_size=config.batch_size, method_type=config.predictor)\n",
    "\n",
    "# Make the ZeroCost predictor ready for prediction\n",
    "# In this case, that involves loading the data loaders for CIFAR10\n",
    "predictor.pre_process()\n",
    "\n",
    "# Create the models to score\n",
    "n = 10\n",
    "print(f'Sampling {n} models...')\n",
    "models = [sample_and_parse_graph() for i in range(n)]\n",
    "\n",
    "# Score each model\n",
    "print('Scoring models with predictor ...')\n",
    "scores = [predictor.query(model) for model in models]\n",
    "\n",
    "# Query benchmarks to get the actual scores\n",
    "print('Querying benchmarks for actual scores...')\n",
    "actual_scores = [\n",
    "        model.query(\n",
    "            metric=Metric.VAL_ACCURACY,\n",
    "            dataset='cifar10',\n",
    "            dataset_api=dataset_api\n",
    "        ) for model in models\n",
    "    ]\n",
    "\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f56cf4f",
   "metadata": {},
   "source": [
    "The Kendall Tau correlation of the predicted and actual scores is the metric of interest in the competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ba8a742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KendalltauResult(correlation=0.5555555555555555, pvalue=0.02860945767195767)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "stats.kendalltau(scores, actual_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c18c14",
   "metadata": {},
   "source": [
    "To make the evaluation of predictors more convenient, `PredictorEvaluator` class is provided to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17d2ed85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\u001b[32m[04/04 21:03:32 nl.evaluators.zc_evaluator]: \u001b[0mLoading the test set...\n",
      "\u001b[32m[04/04 21:03:32 nl.evaluators.zc_evaluator]: \u001b[0mSampling from search space...\n",
      "\u001b[32m[04/04 21:03:35 nl.evaluators.zc_evaluator]: \u001b[0mLoading the training set\n",
      "\u001b[32m[04/04 21:03:35 nl.evaluators.zc_evaluator]: \u001b[0mSampling from search space...\n",
      "\u001b[32m[04/04 21:03:35 nl.evaluators.zc_evaluator]: \u001b[0mFitting the predictor...\n",
      "\u001b[32m[04/04 21:03:35 nl.evaluators.zc_evaluator]: \u001b[0mQuerying the predictor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 14/14 [00:10<00:00,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[04/04 21:03:45 nl.evaluators.zc_evaluator]: \u001b[0mCompute evaluation metrics\n",
      "dataset: cifar10, predictor: synflow, spearman 0.7451\n",
      "\u001b[32m[04/04 21:03:45 nl.evaluators.zc_evaluator]: \u001b[0mmae: 2.561165989669785e+40, rmse: 9.545006077219512e+40, pearson: 0.2369, spearman: 0.7451, kendalltau: 0.5604, kt_2dec: 0.5604, kt_1dec: 0.5604, precision_10: 0.9, precision_20: 0.6, full_ytest: [86.77 71.92 85.18 89.47 87.4  84.85 85.19 89.01 85.17 89.89 87.12 84.12\n",
      " 89.44 85.69], full_testpred: [2.07672438e+19 2.58500748e+06 2.96844875e+25 2.03657231e+35\n",
      " 1.38303827e+31 2.48829083e+32 2.25192877e+23 2.03214661e+26\n",
      " 4.68308787e+15 1.42445038e+39 1.88683860e+19 2.48598392e+06\n",
      " 3.57138584e+41 1.58866766e+18], train_time: 26.0556, fit_time: 0.0, query_time: 0.7487, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5604395604395604"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from naslib.evaluators.zc_evaluator import PredictorEvaluator\n",
    "from naslib.utils import setup_logger\n",
    "import logging\n",
    "\n",
    "# Set up logger\n",
    "logger = setup_logger(config.save + \"/log.log\")\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Change the default test_size in configs\n",
    "config.test_size = 14\n",
    "\n",
    "# Initialize the PredictorEvaluator class\n",
    "predictor_evaluator = PredictorEvaluator(predictor, config=config)\n",
    "predictor_evaluator.adapt_search_space(search_space, dataset_api=dataset_api)\n",
    "\n",
    "# Evaluate the predictor\n",
    "results = predictor_evaluator.evaluate()\n",
    "results[-1]['kendalltau']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf21cae",
   "metadata": {},
   "source": [
    "## Sample Submission\n",
    "\n",
    "Now, you're ready to create a sample submission for the competition. In this example, we're going to write a very simple zero-cost predictor, which simply counts the number of parameters in the model. The predictor thus assigns higher score to bigger models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e646e14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from naslib.predictors.predictor import Predictor\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters())\n",
    "\n",
    "class ZeroCostPredictor(Predictor):\n",
    "    '''Your predictor class MUST be named ZeroCostPredictor'''\n",
    "    def __init__(self):\n",
    "        self.method_type = 'count_params'\n",
    "\n",
    "    def pre_process(self):\n",
    "        pass\n",
    "\n",
    "    def query(self, xtest, info=None):\n",
    "        graph = xtest\n",
    "        score = count_parameters(graph)\n",
    "        # Higher the score, higher the ranking of the model\n",
    "        return score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6e88d7",
   "metadata": {},
   "source": [
    "For the submission to be complete, the class `ZeroCostPredictor` must be saved in a file named `predictor.py` and zipped together with an empty `metdata` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee2a4893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: sample_submission: File exists\n",
      "updating: sample_submission/metadata (stored 0%)\n",
      "updating: sample_submission/predictor.py (deflated 49%)\n"
     ]
    }
   ],
   "source": [
    "!mkdir sample_submission\n",
    "!touch sample_submission/metadata\n",
    "!zip sample_submission.zip sample_submission/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3763893c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
