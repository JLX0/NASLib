{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d18b7c9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca0c673d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/miniconda3/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import fnmatch\n",
    "import pandas as pd\n",
    "import seaborn\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ef16cb",
   "metadata": {},
   "source": [
    "# Unzip NASLib/run/results/bananas_400.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bbc0cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "BENCHMARKS = {\n",
    "#     'nasbench101': ['cifar10'],\n",
    "    'nasbench201': ['cifar10', 'cifar100', 'ImageNet16-120'],\n",
    "    'nasbench301': ['cifar10'],\n",
    "    'transbench101_micro': ['jigsaw', 'class_scene', 'class_object', 'autoencoder', 'normal', 'room_layout', 'segmentsemantic'],\n",
    "    'transbench101_macro': ['jigsaw', 'class_scene', 'class_object', 'autoencoder', 'normal', 'room_layout', 'segmentsemantic']\n",
    "}\n",
    "\n",
    "LABELS = {\n",
    "    'nasbench101': 'NB101',\n",
    "    'nasbench201': 'NB201',\n",
    "    'nasbench301': 'NB301',\n",
    "    'transbench101_micro': 'TNB101_MICRO',\n",
    "    'transbench101_macro': 'TNB101_MACRO',\n",
    "    'cifar10': 'CF10',\n",
    "    'cifar100': 'CF100',\n",
    "    'ImageNet16-120': 'IMGNT',\n",
    "    'jigsaw': 'JIGSAW',\n",
    "    'class_scene': 'SCENE',\n",
    "    'class_object': 'OBJECT',\n",
    "    'autoencoder': 'AUTOENC',\n",
    "    'normal': 'NORMAL',\n",
    "    'room_layout': 'ROOM',\n",
    "    'segmentsemantic': 'SEGMENT',\n",
    "}\n",
    "\n",
    "START_SEED = 9000\n",
    "N_SEEDS = 32\n",
    "N_EPOCHS = 500\n",
    "\n",
    "def find_files(src='../run/results/only_zc', fname='*events.out.tfevents.*'):\n",
    "    matches = []\n",
    "    for root, dirnames, filenames in os.walk(src):\n",
    "        for filename in fnmatch.filter(filenames, fname):\n",
    "            matches.append(os.path.join(root, filename))\n",
    "\n",
    "    return matches\n",
    "\n",
    "def read_file(event_file, tag):\n",
    "    vals = []\n",
    "    for e in tf.train.summary_iterator(event_file):\n",
    "        for v in e.summary.value:\n",
    "            if v.tag == tag:\n",
    "                vals.append(v.simple_value)\n",
    "    return vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5086d1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = find_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6675ef60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../run/results/only_zc/transbench101_micro/jigsaw/zc/9009/fisher-flops-grad_norm-grasp-jacov-l2_norm-nwot-params-plain-snip-zen/events.out.tfevents.1654634872.kisexe12.917366.0',\n",
       " 392)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_files[0], len(all_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ecbf6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores_as_list_of_dict(files):\n",
    "    data = []\n",
    "\n",
    "    for file in files:\n",
    "        components = file.split('/')\n",
    "        zc_names, seed, dataset, search_space = components[-2], components[-3], components[-5], components[-6]\n",
    "\n",
    "        val_accuracies = read_file(file, \"Validation accuracy (top 1)\")\n",
    "        train_accuracies = read_file(file, \"Train accuracy (top 1)\")\n",
    "        \n",
    "        if len(val_accuracies) == 0 or len(train_accuracies) == 0:\n",
    "            continue\n",
    "        \n",
    "        record = {\n",
    "            'search_space': search_space,\n",
    "            'dataset': dataset,\n",
    "            'seed': seed,\n",
    "            'zc_names': zc_names,\n",
    "            'val_accs': val_accuracies,\n",
    "            'train_accs': train_accuracies,\n",
    "        }\n",
    "\n",
    "        data.append(record)\n",
    "\n",
    "    return data\n",
    "\n",
    "def make_df(files):\n",
    "    data = get_scores_as_list_of_dict(files)\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "def clean_df(df):\n",
    "    bad_indices = []\n",
    "\n",
    "    for idx, val_acc in enumerate(df['val_accs']):\n",
    "        if len(val_acc) != N_EPOCHS:\n",
    "            bad_indices.append(idx)\n",
    "\n",
    "    df = df.drop(index=bad_indices)\n",
    "    return df\n",
    "\n",
    "def get_val_train_accs(df, search_space, dataset):\n",
    "    df_ = df[(df['search_space'] == search_space) & (df['dataset'] == dataset)]\n",
    "    \n",
    "    seed_val_accs = []\n",
    "    seed_train_accs = []\n",
    "\n",
    "    for seed in range(START_SEED, START_SEED + N_SEEDS):\n",
    "        try:\n",
    "            vals = df_[df_['seed'] == str(seed)]['val_accs'].item()\n",
    "            train_accs = df_[df_['seed'] == str(seed)]['train_accs'].item()\n",
    "            seed_val_accs.append(vals)\n",
    "            seed_train_accs.append(train_accs)\n",
    "        except:\n",
    "            print(df_[df_['seed'] == str(seed)]['val_accs'])\n",
    "    \n",
    "    return np.array(seed_val_accs), np.array(seed_train_accs)\n",
    "\n",
    "def plot(x, title, xlabel, ylabel, figsize=(18, 12)):\n",
    "    \n",
    "    x_mean = np.mean(x, axis=0)\n",
    "    x_std = np.std(x, axis=0)\n",
    "    \n",
    "    plt.figure(figsize=figsize, dpi=200)\n",
    "    plt.title(title, fontsize=20)\n",
    "    plt.plot(x_mean)\n",
    "\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.fill_between(range(len(x_mean)), x_mean+x_std, x_mean-x_std, alpha=0.6)\n",
    "\n",
    "\n",
    "def plot_multiple(x_only_zc, x_only_adj, x_zc, title, xlabel, ylabel, figsize=(18, 12)):\n",
    "    plt.figure(figsize=figsize, dpi=200)\n",
    "    plt.title(title, fontsize=20)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.grid(True)\n",
    "\n",
    "    titles = ('ONLY_ZC', 'ONLY_ADJ', 'BOTH')\n",
    "    \n",
    "    for idx, x in enumerate((x_only_zc, x_only_adj, x_zc)):\n",
    "        x_mean = np.mean(x, axis=0)\n",
    "        x_std = np.std(x, axis=0)\n",
    "        plt.plot(x_mean, label=titles[idx])\n",
    "        plt.fill_between(range(len(x_mean)), x_mean+x_std, x_mean-x_std, alpha=0.4)\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "def plot_for_search_space(df, search_space):\n",
    "    for dataset in BENCHMARKS[search_space]:\n",
    "        val_accs, train_accs = get_val_train_accs(df, search_space, dataset)\n",
    "        plot(val_accs, f'{LABELS[search_space]} {LABELS[dataset]}', 'Epochs', 'Validation Accuracy (Top 1)')\n",
    "\n",
    "def plot_search_space(search_space, only_zc_df, only_adj_df, zc_df):    \n",
    "    for dataset in BENCHMARKS[search_space]:\n",
    "        only_zc_vals, _ = get_val_train_accs(only_zc_df, search_space, dataset)\n",
    "        only_adj_vals, _ = get_val_train_accs(only_adj_df, search_space, dataset)\n",
    "        zc_vals, _ = get_val_train_accs(zc_df, search_space, dataset)\n",
    "\n",
    "        plot_multiple(only_zc_vals, only_adj_vals, zc_vals, f'{LABELS[search_space]} {LABELS[dataset]}', 'Epochs', 'Validation Accuracy (Top 1)' )\n",
    "\n",
    "def save_df(df, name):\n",
    "    df.to_pickle(name)\n",
    "\n",
    "def load_df(name):\n",
    "    return pd.read_pickle(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ed0d9b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df = make_df(all_files)\n",
    "# plot_for_search_space(df, 'transbench101_macro')\n",
    "# plot_for_search_space(df, 'nasbench301')\n",
    "# plot_for_search_space(df, 'nasbench201')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3de1a764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(392, 392, 392)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "only_zc_files = find_files(src='../run/results/only_zc')\n",
    "only_adj_files = find_files(src='../run/results/only_adjacency')\n",
    "zc_files = find_files(src='../run/results/zc_and_adjacency')\n",
    "\n",
    "len(only_zc_files), len(only_adj_files), len(zc_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9a4483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/miniconda3/lib/python3.8/site-packages/tensorflow/python/summary/summary_iterator.py:31: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n"
     ]
    }
   ],
   "source": [
    "only_zc_df = make_df(only_zc_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb36600",
   "metadata": {},
   "outputs": [],
   "source": [
    "only_adj_df = make_df(only_adj_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1df226e",
   "metadata": {},
   "outputs": [],
   "source": [
    "zc_df = make_df(zc_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bab5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_df(only_zc_df, 'only_zc.pkl')\n",
    "# save_df(only_adj_df, 'only_adj.pkl')\n",
    "# save_df(zc_df, 'zc_and_adj.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8547ff76",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(only_adj_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3508a06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "only_zc_df = clean_df(only_zc_df)\n",
    "only_adj_df = clean_df(only_adj_df)\n",
    "zc_df = clean_df(zc_df)\n",
    "\n",
    "len(only_zc_df), len(only_adj_df), len(zc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37da6878",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_multiple(x_only_zc, x_only_adj, x_zc, title, xlabel, ylabel, figsize=(6, 4)):\n",
    "    plt.figure(figsize=figsize, dpi=200)\n",
    "    plt.title(title, fontsize=20)\n",
    "    plt.xlabel(xlabel)\n",
    "    if 'AUTOENC' in title or 'NORMAL' in title:\n",
    "        ylabel = 'SSIM'\n",
    "    elif 'SEGMENT' in title:\n",
    "        ylabel = 'mIoU'\n",
    "    elif 'ROOM' in title:\n",
    "        ylabel = 'L2 Loss'\n",
    "    else:\n",
    "        ylabel = 'Accuracy (%)'\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xscale('log')\n",
    "    #plt.yscale('log')\n",
    "    plt.grid(True)\n",
    "\n",
    "    titles = ('Encoding', 'ZCPs', 'Encoding + ZCPs')\n",
    "    \n",
    "    os.makedirs('bananas', exist_ok=True)\n",
    "    \n",
    "    title_to_lim = {\n",
    "        'NB201 CF10': [90, 92],\n",
    "        'NB201 CF100': [71, 73],\n",
    "        'NB201 IMGNT': [46, 46.6],\n",
    "        'NB301 CF10': [94, 94.6],\n",
    "        'TNB101_MICRO JIGSAW': [94.5, 95],\n",
    "        'TNB101_MICRO SCENE': [54.25, 54.9],\n",
    "        'TNB101_MICRO OBJECT': [44.75, 45.75],\n",
    "        'TNB101_MICRO AUTOENC': [0.54, 0.58],\n",
    "        'TNB101_MICRO NORMAL': [0.56, 0.58],\n",
    "        'TNB101_MICRO ROOM': [-0.625, -0.6],\n",
    "        'TNB101_MICRO SEGMENT': [94.6, 94.8],\n",
    "        'TNB101_MACRO JIGSAW': [96.5, 97],\n",
    "        'TNB101_MACRO SCENE': [56.5, 57],\n",
    "        'TNB101_MACRO OBJECT': [47, 47.6],\n",
    "        'TNB101_MACRO AUTOENC': [0.7, 0.78],\n",
    "        'TNB101_MACRO NORMAL': [0.62, 0.65],\n",
    "        'TNB101_MACRO ROOM': [-0.6, -0.56],\n",
    "        'TNB101_MACRO SEGMENT': [94.95, 95.1],   \n",
    "    }\n",
    "    plt.ylim(title_to_lim[title])\n",
    "    plt.xlim([10, 200])\n",
    "    \n",
    "    for idx, x in enumerate((x_only_adj, x_only_zc, x_zc)):\n",
    "#         print(idx, x)\n",
    "        x_mean = np.mean(x, axis=0)\n",
    "        print(idx, x_mean.shape)\n",
    "        x_std = np.std(x, axis=0)/np.sqrt(10)\n",
    "        plt.plot(x_mean, label=titles[idx])\n",
    "        plt.fill_between(range(len(x_mean)), x_mean+x_std, x_mean-x_std, alpha=0.2)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.savefig('bananas/{}.pdf'.format(title.replace(' ', '_')), bbox_inches='tight')\n",
    "\n",
    "plot_search_space('nasbench201', only_zc_df, only_adj_df, zc_df)\n",
    "plot_search_space('nasbench301', only_zc_df, only_adj_df, zc_df)\n",
    "plot_search_space('transbench101_micro', only_zc_df, only_adj_df, zc_df)\n",
    "# plot_search_space('transbench101_macro', only_zc_df, only_adj_df, zc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98f719f",
   "metadata": {},
   "outputs": [],
   "source": [
    "only_zc_df[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b815932",
   "metadata": {},
   "outputs": [],
   "source": [
    "only_adj_df[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6213f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.mean(only_adj_df, axis=0)\n",
    "result[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43e203e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "only_zc_df['val_accs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3e13ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
